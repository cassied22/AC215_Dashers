---
- name: "Deploy Kubernetes workloads and networking"
  hosts: localhost
  gather_facts: false

  vars:
    cluster_name: "daily-meal-cluster"

  tasks:
  - name: "Copy docker tag file"
    copy:
      src: .docker-tag
      dest: .docker-tag
      mode: 0644
    when: cluster_state == "present"

  - name: "Get docker tag"
    shell: "cat .docker-tag"
    register: tag
    when: cluster_state == "present"

  - name: "Print tag"
    debug:
      var: tag
    when: cluster_state == "present"

  - name: "Create/Update GCP service account credentials as a Secret"
    k8s:
      state: present
      namespace: "{{cluster_name}}-namespace"
      definition:
        apiVersion: v1
        kind: Secret
        metadata:
          name: llm-service-key
        type: Opaque
        data:
          # Encode the file content to base64 and store it in the secret
          llm-service.json: "{{ lookup('file', '../secrets/llm-service-account-cassie.json') | b64encode }}"
    register: create_gcp_secret_op
    when: cluster_state == "present"

  - name: "Print Create GCP Secret Output"
    debug:
      var: create_gcp_secret_op
    when: cluster_state == "present"

  - name: "Create/Update OpenAI API key as a Secret"
    k8s:
      state: present
      namespace: "{{cluster_name}}-namespace"
      definition:
        apiVersion: v1
        kind: Secret
        metadata:
          name: openai-key
        type: Opaque
        data:
          # Encode the file content to base64 and store it in the secret
          openai-key.json: "{{ lookup('file', '../secrets/openai-key.json') | b64encode }}"
    register: create_openai_secret_op
    when: cluster_state == "present"

  - name: "Print Create OpenAI Secret Output"
    debug:
      var: create_openai_secret_op
    when: cluster_state == "present"


  # - name: Importing GCP service account credentials as a Secret
  #   shell: |
  #     #!/bin/bash
  #     kubectl create secret generic llm-service-key \
  #       --from-file=llm-service.json=../secrets/llm-service-account-cassie.json \
  #       --namespace="{{cluster_name}}-namespace"
  #   register: create_gcp_secret_op
  #   ignore_errors: yes
  #   when: cluster_state == "present"
  
  # - name: "Print Create GCP Secret Output"
  #   debug:
  #     var: create_gcp_secret_op
  #   when: cluster_state == "present"

  # - name: Importing OpenAI API key as a Secret
  #   shell: |
  #     #!/bin/bash
  #     kubectl create secret generic openai-key \
  #       --from-file=openai-key.json=../secrets/openai-key.json \
  #       --namespace="{{cluster_name}}-namespace"
  #   register: create_openai_secret_op
  #   ignore_errors: yes
  #   when: cluster_state == "present"

  # - name: "Print Create OpenAI Secret Output"
  #   debug:
  #     var: create_openai_secret_op
  #   when: cluster_state == "present"
  
  - name: "Create Deployment for Frontend"
    k8s:
      state: present
      definition:
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: frontend
          namespace: "{{cluster_name}}-namespace"
        spec:
          selector:
            matchLabels:
              run: frontend
          template:
            metadata:
              labels:
                run: frontend
            spec:
              containers:
              - image: "gcr.io/{{ gcp_project }}/daily-meal-frontend-react:{{ tag.stdout}}"
                imagePullPolicy: IfNotPresent
                name: frontend
                ports:
                - containerPort: 3000
                  protocol: TCP
    when: cluster_state == "present"

  - name: "Create Deployment for ChromaDB"
    k8s:
      state: present
      definition:
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: recipe-rag-chromadb
          namespace: "{{cluster_name}}-namespace"
        spec:
          selector:
            matchLabels:
              run: recipe-rag-chromadb
          template:
            metadata:
              labels:
                run: recipe-rag-chromadb
            spec:
              containers:
              - name: recipe-rag-chromadb
                image: chromadb/chroma:0.5.18
                ports:
                - containerPort: 8000
                  protocol: TCP
                env:
                - name: IS_PERSISTENT
                  value: "TRUE"
                - name: ANONYMIZED_TELEMETRY
                  value: "FALSE"
              #   volumeMounts:
              #   - name: chromadb-storage
              #     mountPath: /chroma/chroma
              # volumes:
              # - name: chromadb-storage
              #   persistentVolumeClaim:
              #     claimName: chromadb-pvc
    when: cluster_state == "present"

  - name: "Create Deployment for API Service"
    k8s:
      state: present
      definition:
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: api
          namespace: "{{cluster_name}}-namespace"
        spec:
          selector:
            matchLabels:
              run: api
          template:
            metadata:
              labels:
                run: api
            spec:
              volumes:
                - name: persistent-vol
                  emptyDir: {}
                - name: google-cloud-key
                  secret:
                    secretName: llm-service-key
                - name: openai-key
                  secret:
                    secretName: openai-key
              containers:
              - image: gcr.io/{{ gcp_project }}/daily-meal-api-service:{{ tag.stdout}}
                imagePullPolicy: IfNotPresent
                name: api
                ports:
                - containerPort: 9000
                  protocol: TCP
                volumeMounts:
                  - name: persistent-vol
                    mountPath: /persistent
                  - name: google-cloud-key
                    mountPath: /secrets
                env:
                  - name: GOOGLE_APPLICATION_CREDENTIALS
                    value: /secrets/llm-service.json
                  - name: OPENAI_API_KEY
                    value: /secrets/openai-key.json
                  # - name: GCS_BUCKET_NAME
                  #   value: cheese-app-models
                  - name: CHROMADB_HOST
                    value: recipe-rag-chromadb
                  - name: CHROMADB_PORT
                    value: "8000"
                  - name: GCP_PROJECT
                    value: "{{ gcp_project }}"
    when: cluster_state == "present"

  - name: "Create Service for Frontend"
    k8s:
      state: present
      definition:
        apiVersion: v1
        kind: Service
        metadata:
          name: frontend
          namespace: "{{cluster_name}}-namespace"
        spec:
          ports:
          - port: 3000
            protocol: TCP
            targetPort: 3000
          selector:
            run: frontend
          type: NodePort
    when: cluster_state == "present"

  - name: "Create Service for ChromaDB"
    k8s:
      state: present
      definition:
        apiVersion: v1
        kind: Service
        metadata:
          name: recipe-rag-chromadb
          namespace: "{{cluster_name}}-namespace"
        spec:
          ports:
          - port: 8000
            protocol: TCP
            targetPort: 8000
          selector:
            run: recipe-rag-chromadb
          type: NodePort
    when: cluster_state == "present"

  - name: "Delete existing vector-db-loader job if it exists"
    k8s:
      state: absent
      api_version: batch/v1
      kind: Job
      namespace: "{{cluster_name}}-namespace"
      name: vector-db-loader
    ignore_errors: yes
    when: cluster_state == "present"

  - name: "Wait for job deletion to complete"
    shell: "kubectl wait --for=delete job/vector-db-loader -n {{cluster_name}}-namespace"
    ignore_errors: yes
    when: cluster_state == "present"

  - name: "Create Job for Loading Vector DB"
    k8s:
      state: present
      definition:
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: vector-db-loader
          namespace: "{{cluster_name}}-namespace"
        spec:
          template:
            spec:
              initContainers:
              - name: wait-for-chromadb
                image: busybox:1.28
                command: ['sh', '-c', 
                  'until wget --spider -S http://recipe-rag-chromadb:8000/api/v1/heartbeat 2>&1 | grep "HTTP/1.1 200"; 
                  do echo "Waiting for ChromaDB..."; sleep 5; done;']
              containers:
              - name: vector-db-loader
                image: "gcr.io/{{ gcp_project }}/daily-meal-vector-db-cli:{{ tag.stdout}}"
                env:
                - name: GCP_PROJECT
                  value: "{{ gcp_project }}"
                - name: CHROMADB_HOST
                  value: "recipe-rag-chromadb"
                - name: CHROMADB_PORT
                  value: "8000"
                - name: GOOGLE_APPLICATION_CREDENTIALS
                  value: "/secrets/llm-service.json"
                volumeMounts:
                - name: google-cloud-key
                  mountPath: /secrets
              volumes:
              - name: google-cloud-key
                secret:
                  secretName: llm-service-key
              restartPolicy: Never
          backoffLimit: 2
    when: cluster_state == "present"

  - name: "Wait for vector-db-loader job to complete"
    shell: |
      kubectl wait --for=condition=complete job/vector-db-loader -n {{cluster_name}}-namespace --timeout=600s
    register: wait_job_result
    retries: 0
    delay: 60
    until: wait_job_result.rc == 0
    when: cluster_state == "present"

  - name: "Verify vector-db-loader job succeeded"
    shell: |
      kubectl get job vector-db-loader -n {{cluster_name}}-namespace -o jsonpath='{.status.conditions[?(@.type=="Complete")].status}'
    register: job_status
    failed_when: job_status.stdout != "True"
    when: cluster_state == "present"

  - name: "Create Service for API Service"
    k8s:
      state: present
      definition:
        apiVersion: v1
        kind: Service
        metadata:
          name: api
          namespace: "{{cluster_name}}-namespace"
        spec:
          ports:
          - port: 9000
            protocol: TCP
            targetPort: 9000
          selector:
            run: api
          type: NodePort
    when: cluster_state == "present"

  - name: Wait for Ingress Nginx to get ready
    shell: |
      #!/bin/bash
      kubectl get service nginx-ingress-controller --namespace="{{cluster_name}}-namespace" -ojson | jq -r '.status.loadBalancer.ingress[].ip'
    register: nginx_ingress
    delay: 10
    retries: 20
    until: nginx_ingress.stderr == ""
    when: cluster_state == "present"

  - name: Set Nginx Ingress IP
    set_fact:
      nginx_ingress_ip: "{{nginx_ingress.stdout}}"
    when: cluster_state == "present"

  - name: Debug Ingress Nginx IP Address
    debug:
      msg: "Ingress Nginx IP Address: {{ nginx_ingress_ip }}"
    when: cluster_state == "present"

  - name: Debug vars
    debug:
      var: nginx_ingress_ip
      verbosity: 0
    when: cluster_state == "present"

  - name: "Create Ingress Controller"
    k8s:
      state: present
      definition:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: ingress-resource
          namespace: "{{cluster_name}}-namespace"
          annotations:
            kubernetes.io/ingress.class: "nginx"
            nginx.ingress.kubernetes.io/ssl-redirect: "false"
            nginx.org/rewrites: "serviceName=frontend rewrite=/;serviceName=api rewrite=/"
        spec:
          rules:
          - host: "{{ nginx_ingress_ip }}.sslip.io" # Host requires a domain and not just an IP
            http:
              paths:
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: frontend
                    port:
                      number: 3000
              - path: /api/
                pathType: Prefix
                backend:
                  service:
                    name: api
                    port:
                      number: 9000
    when: cluster_state == "present"